{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11934"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(\"data.txt\", sep='  ', header=None)\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:16]\n",
    "y = data.iloc[:,16:18]\n",
    "#y2 =  data.iloc[:,17]\n",
    "x = x.drop(columns = [8,11,0,1,3,5,6,13])\n",
    "#x = (x - x.mean()) / (x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8353"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return abs(x) * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLu(x):\n",
    "    return 1. *(x > 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3) #generates a value between 3\n",
    "w0 = np.random.random((8,50)) - 1 #between layers 0 and 1\n",
    "w1 = np.random.random((50,26)) - 1 #between layers 1 and 2\n",
    "w2 = np.random.random((26,8)) - 1\n",
    "w3 = np.random.random((8,2)) - 1\n",
    "\n",
    "b = np.random.random((1,1)) - 1\n",
    "# b1 = np.random.random((1,1)) - 1\n",
    "# b2 = np.random.random((1,1)) - 1\n",
    "# b3 = np.random.random((1,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(data_in , w0, w1 ,w2,w3, b):\n",
    "    layer0 = data_in\n",
    "    layer1 = ReLu(np.dot(layer0,w0)+b0)\n",
    "    layer2 = ReLu(np.dot(layer1,w1)+b1)\n",
    "    layer3 = ReLu(np.dot(layer2,w2)+b2)\n",
    "    layer4 = np.dot(layer3,w3)\n",
    "    \n",
    "    return layer0,layer1,layer2,layer3,layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(layer0,layer1,layer2,layer3,layer4, actual_y, w0,w1,w2,w3,b,learning_rate, i):\n",
    "    \n",
    "    l4_error = layer4 - actual_y\n",
    "    l4_delta = l4_error\n",
    "    dh4 = np.dot(layer3.T,l4_delta)\n",
    "    \n",
    "    l3_error = np.dot(l4_delta,w3.T)\n",
    "    l3_delta = l3_error * dReLu(layer3)\n",
    "    dh3 = np.dot(layer2.T, l3_delta) #layer 1 change\n",
    "    \n",
    "    l2_error = np.dot(l3_delta,w2.T)\n",
    "    l2_delta = l2_error * dReLu(layer2)\n",
    "    dh2 = np.dot(layer1.T,l2_delta)#layer2 changes\n",
    "    \n",
    "    l1_error = np.dot(l2_delta,w1.T)\n",
    "    l1_delta = l1_error * dReLu(layer1)\n",
    "    dh1 = np.dot(layer0.T, l1_delta)#layer 3 changes\n",
    "    \n",
    "    w3 = w3 - (learning_rate * dh4)\n",
    "    w2 = w2 - (learning_rate * dh3)\n",
    "    w1 = w1 - (learning_rate * dh2)\n",
    "    w0 = w0 - (learning_rate * dh1)\n",
    "#    # b3 = b3 - (learning_rate * np.mean(l4_delta))\n",
    "#     b2 = b2 - (learning_rate * np.mean(l3_delta))\n",
    "#     b1 = b1 - (learning_rate * np.mean(l2_delta))#we use l2_delta as we get a unit value when differentiation with b is done\n",
    "    #b = b - (learning_rate * np.mean(l4_delta))\n",
    "    \n",
    "    if i%1 == 0 and (i!=0):\n",
    "        loss = np.mean(np.power(layer4 - actual_y,2))\n",
    "        loss_curve.append(loss)\n",
    "        iters.append(int(i))\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            print('\\n', int(i),loss)\n",
    "    \n",
    "    return w0,w1,w2,w3,b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "loss_curve = []\n",
    "iters = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 2000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 3000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 4000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 5000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 6000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 7000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 8000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n",
      "\n",
      " 9000 16    0.950793\n",
      "17    0.975215\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    layer0,layer1,layer2,layer3,layer4 = feed_forward(xtrain,w0,w1,w2,w3,b)\n",
    "    w0,w1,w2,w3,b = back_propogation(layer0,layer1,layer2,layer3,layer4,ytrain, w0,w1,w2,w3,b,0.05,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(iters,loss_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = feed_forward(xtest.iloc[:,:],w0,w1,w2,w3,b)\n",
    "c[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5818</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8324</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5808</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9812</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7824</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>0.957</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10571</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0.953</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>0.967</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8629</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10103</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>0.987</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>0.965</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9846</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>0.975</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11299</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11317</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6829</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6945</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0.954</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7109</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3581 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          16     17\n",
       "2166   0.959  0.981\n",
       "4459   0.969  0.976\n",
       "10885  0.996  0.988\n",
       "28     0.950  0.978\n",
       "8362   0.985  0.994\n",
       "433    0.951  0.997\n",
       "5818   0.974  0.997\n",
       "7698   0.982  0.998\n",
       "8324   0.985  0.989\n",
       "3947   0.966  0.997\n",
       "3902   0.966  0.992\n",
       "5808   0.974  0.996\n",
       "9812   0.991  0.999\n",
       "2262   0.959  0.992\n",
       "7824   0.983  0.986\n",
       "2136   0.959  0.978\n",
       "1455   0.956  0.980\n",
       "610    0.952  0.990\n",
       "1307   0.955  0.990\n",
       "454    0.951  0.999\n",
       "1665   0.957  0.978\n",
       "10571  0.995  0.979\n",
       "2118   0.959  0.976\n",
       "10158  0.993  0.985\n",
       "3626   0.965  0.987\n",
       "528    0.952  0.981\n",
       "243    0.951  0.976\n",
       "5458   0.973  0.983\n",
       "9102   0.988  0.998\n",
       "933    0.953  1.000\n",
       "...      ...    ...\n",
       "4018   0.967  0.979\n",
       "8629   0.986  0.997\n",
       "10103  0.993  0.979\n",
       "4973   0.971  0.981\n",
       "8885   0.987  1.000\n",
       "4482   0.969  0.979\n",
       "11583  0.999  0.988\n",
       "3654   0.965  0.991\n",
       "9846   0.992  0.977\n",
       "8656   0.986  1.000\n",
       "8780   0.987  0.988\n",
       "7153   0.980  0.989\n",
       "10151  0.993  0.984\n",
       "2419   0.960  0.983\n",
       "5890   0.975  0.979\n",
       "11299  0.998  0.982\n",
       "113    0.950  0.987\n",
       "7351   0.981  0.985\n",
       "11317  0.998  0.984\n",
       "5563   0.973  0.995\n",
       "1570   0.956  0.993\n",
       "1372   0.955  0.997\n",
       "895    0.953  0.996\n",
       "6829   0.979  0.979\n",
       "6945   0.979  0.992\n",
       "1295   0.955  0.988\n",
       "1167   0.954  1.000\n",
       "796    0.953  0.985\n",
       "7109   0.980  0.984\n",
       "6173   0.976  0.984\n",
       "\n",
       "[3581 rows x 2 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630811347389214"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(c[4],ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
